{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Backtest - Crypto Spread Arbitrage - Shortcut Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "from datetime import date, datetime, timedelta\n",
    "\n",
    "import cryptomart as cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import requests\n",
    "import vectorbt as vbt\n",
    "\n",
    "import app\n",
    "from app import bq_util\n",
    "from app.enums import Exchange, InstrumentType, Interval, OHLCVColumn, SpreadColumn\n",
    "from app.errors import BigQueryError, ExchangeAPIError, MissingDataError, NotSupportedError\n",
    "from app.feeds import Spread\n",
    "from app.globals import STUDY_END_DATE, STUDY_INST_TYPES, STUDY_START_DATE, STUDY_TIME_RANGE, BLACKLISTED_SYMBOLS\n",
    "from app import util\n",
    "from app.vbt_backtest_chained import from_order_func_wrapper_chained\n",
    "\n",
    "# Global APIs / Constants\n",
    "cm_client = cm.Client(quiet=True)\n",
    "\n",
    "# We may have different identifiers for different strategies / different datasets used\n",
    "backtest_identifier = \"spread_arb_v2\"\n",
    "z_score_period = 30\n",
    "data_start_filter = pd.to_datetime(datetime(2022, 10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger(\"cryptomart\").setLevel(\"WARNING\")\n",
    "@util.cached(\"/tmp/cache/all_ohlcv\", refresh=False, identifiers=[backtest_identifier])\n",
    "def all_ohlcv() -> pd.DataFrame:\n",
    "    \"\"\"Get OHLCV for all instruments\"\"\"\n",
    "    ohlcvs = pd.DataFrame(index=pd.MultiIndex.from_arrays([[], [], []], names=[\"exchange\", \"inst_type\", \"symbol\"]))\n",
    "\n",
    "    for exchange in Exchange:\n",
    "        for inst_type in STUDY_INST_TYPES:\n",
    "            instruments = cm_client.instrument_info(exchange, inst_type)\n",
    "            instruments = instruments[~instruments[\"cryptomart_symbol\"].isin(BLACKLISTED_SYMBOLS)]\n",
    "            for symbol in instruments[\"cryptomart_symbol\"]:\n",
    "                try:\n",
    "                    fr = cm_client.ohlcv(\n",
    "                        exchange,\n",
    "                        symbol,\n",
    "                        inst_type,\n",
    "                        STUDY_START_DATE,\n",
    "                        STUDY_END_DATE,\n",
    "                        cache_kwargs={\"disabled\": False},\n",
    "                    )\n",
    "                except NotSupportedError:\n",
    "                    # Instrument not supported by exchange\n",
    "                    continue\n",
    "                ohlcvs.at[(exchange, inst_type, symbol), \"ohlcv\"] = pickle.dumps(fr)\n",
    "\n",
    "    return ohlcvs\n",
    "\n",
    "ohlcvs = all_ohlcv()\n",
    "ohlcvs[\"rows\"] = ohlcvs[\"ohlcv\"].apply(lambda x: sum(~pickle.loads(x).close.isna()))\n",
    "ohlcvs[\"missing_rows\"] = ohlcvs[\"ohlcv\"].apply(lambda x: len(pickle.loads(x).missing_rows))\n",
    "ohlcvs[\"earliest_time\"] = ohlcvs[\"ohlcv\"].apply(lambda x: pickle.loads(x).earliest_time)\n",
    "ohlcvs[\"latest_time\"] = ohlcvs[\"ohlcv\"].apply(lambda x: pickle.loads(x).latest_time)\n",
    "ohlcvs[\"gaps\"] = ohlcvs[\"ohlcv\"].apply(lambda x: pickle.loads(x).gaps)\n",
    "ohlcvs = ohlcvs[ohlcvs[\"missing_rows\"] == 0]\n",
    "instrument_data = ohlcvs.copy()[[\"ohlcv\"]]\n",
    "\n",
    "# Exchange-wide taker fee: https://www.binance.com/en/fee/futureFee\n",
    "\n",
    "# BINANCE\n",
    "fee_info_binance = cm_client.binance.instrument_info(\"perpetual\")\n",
    "fee_info_binance = fee_info_binance.set_index(\"cryptomart_symbol\").rename_axis(index=\"symbol\")\n",
    "fee_info_binance = (\n",
    "    fee_info_binance[[\"maintMarginPercent\", \"requiredMarginPercent\"]]\n",
    "    .rename(columns={\"maintMarginPercent\": \"maint_margin\", \"requiredMarginPercent\": \"init_margin\"})\n",
    "    .astype(float)\n",
    "    .apply(lambda x: x / 100)\n",
    ")\n",
    "fee_info_binance = fee_info_binance.assign(fee_pct=0.0004, fee_fixed=0)\n",
    "\n",
    "# BITMEX\n",
    "fee_info_bitmex = cm_client.bitmex.instrument_info(\"perpetual\")\n",
    "fee_info_bitmex = fee_info_bitmex.set_index(\"cryptomart_symbol\").rename_axis(index=\"symbol\")\n",
    "fee_info_bitmex = fee_info_bitmex[[\"maintMargin\", \"initMargin\", \"takerFee\"]].rename(\n",
    "    columns={\"maintMargin\": \"maint_margin\", \"initMargin\": \"init_margin\", \"takerFee\": \"fee_pct\"}\n",
    ")\n",
    "fee_info_bitmex = fee_info_bitmex.assign(fee_fixed=0)\n",
    "fee_info_bitmex\n",
    "\n",
    "# BYBIT\n",
    "@cached(\"/tmp/cache/fee_margin_data\", refresh=False, path_seperators=[\"exchange\"])\n",
    "def bybit_get_single_margin(exchange_symbol, exchange=\"bybit\"):\n",
    "    url = os.path.join(cm_client.bybit.base_url, \"public\", \"linear\", \"risk-limit\")\n",
    "    params = {\"symbol\": exchange_symbol}\n",
    "    request = requests.Request(\"GET\", url=url, params=params)\n",
    "    response = cm_client.bybit.dispatcher.send_request(request)\n",
    "    response = cm.interfaces.api.APIInterface.extract_response_data(\n",
    "        response, [\"result\"], [\"ret_code\"], 0, [\"ret_msg\"], raw=True\n",
    "    )\n",
    "    risk_tiers = pd.DataFrame(response)\n",
    "    lowest_risk_tier = risk_tiers[risk_tiers.limit == risk_tiers.limit.min()]\n",
    "    return (\n",
    "        lowest_risk_tier[[\"maintain_margin\", \"starting_margin\"]]\n",
    "        .rename(columns={\"maintain_margin\": \"maint_margin\", \"starting_margin\": \"init_margin\"})\n",
    "        .iloc[0]\n",
    "    )\n",
    "\n",
    "\n",
    "fee_info_bybit = cm_client.bybit.instrument_info(\"perpetual\")\n",
    "fee_info_bybit = fee_info_bybit.set_index(\"cryptomart_symbol\").rename_axis(index=\"symbol\")\n",
    "\n",
    "fee_info_bybit = pd.concat([fee_info_bybit, fee_info_bybit.exchange_symbol.apply(bybit_get_single_margin)], axis=1)\n",
    "fee_info_bybit = fee_info_bybit[[\"maint_margin\", \"init_margin\", \"taker_fee\"]].rename(columns={\"taker_fee\": \"fee_pct\"})\n",
    "fee_info_bybit = fee_info_bybit.assign(fee_fixed=0)\n",
    "fee_info_bybit\n",
    "\n",
    "# GATEIO\n",
    "# gateio does not provide init margin rate. Set to NaN and fill with the average of the other exchanges\n",
    "fee_info_gateio = cm_client.gateio.instrument_info(\"perpetual\")\n",
    "fee_info_gateio = fee_info_gateio.set_index(\"cryptomart_symbol\").rename_axis(index=\"symbol\")\n",
    "fee_info_gateio = fee_info_gateio[[\"taker_fee_rate\", \"maintenance_rate\"]].rename(\n",
    "    columns={\"taker_fee_rate\": \"fee_pct\", \"maintenance_rate\": \"maint_margin\"}\n",
    ")\n",
    "fee_info_gateio = fee_info_gateio.assign(init_margin=np.nan)\n",
    "fee_info_gateio = fee_info_gateio.assign(fee_fixed=0)\n",
    "fee_info_gateio = fee_info_gateio[[\"maint_margin\", \"init_margin\", \"fee_pct\", \"fee_fixed\"]]\n",
    "fee_info_gateio\n",
    "\n",
    "# KUCOIN\n",
    "fee_info_kucoin = cm_client.kucoin.instrument_info(\"perpetual\")\n",
    "fee_info_kucoin = fee_info_kucoin.set_index(\"cryptomart_symbol\").rename_axis(index=\"symbol\")\n",
    "fee_info_kucoin = fee_info_kucoin[[\"maintainMargin\", \"initialMargin\", \"takerFeeRate\", \"makerFixFee\"]].rename(\n",
    "    columns={\n",
    "        \"maintainMargin\": \"maint_margin\",\n",
    "        \"initialMargin\": \"init_margin\",\n",
    "        \"takerFeeRate\": \"fee_pct\",\n",
    "        \"makerFixFee\": \"fee_fixed\",\n",
    "    }\n",
    ")\n",
    "fee_info_kucoin\n",
    "\n",
    "# OKEX\n",
    "# Exchange-wide taker fee: https://www.okx.com/fees\n",
    "@cached(\"/tmp/cache/fee_margin_data\", refresh=False, path_seperators=[\"exchange\"])\n",
    "def okex_get_single_margin(exchange_symbol, exchange=\"okex\"):\n",
    "    url = os.path.join(cm_client.okex.base_url, \"api\", \"v5\", \"public\", \"position-tiers\")\n",
    "    params = {\"instType\": \"SWAP\", \"tdMode\": \"isolated\", \"uly\": exchange_symbol}\n",
    "    request = requests.Request(\"GET\", url=url, params=params)\n",
    "    response = cm_client.okex.dispatcher.send_request(request)\n",
    "    response = cm.interfaces.api.APIInterface.extract_response_data(\n",
    "        response, [\"data\"], [\"code\"], \"0\", [\"msg\"], raw=True\n",
    "    )\n",
    "    risk_tiers = pd.DataFrame(response)\n",
    "    return (\n",
    "        risk_tiers.loc[risk_tiers.tier == \"2\", [\"mmr\", \"imr\"]]\n",
    "        .rename(columns={\"mmr\": \"maint_margin\", \"imr\": \"init_margin\"})\n",
    "        .iloc[0]\n",
    "    )\n",
    "\n",
    "\n",
    "fee_info_okex = cm_client.okex.instrument_info(\"perpetual\")\n",
    "fee_info_okex = fee_info_okex.set_index(\"cryptomart_symbol\").rename_axis(index=\"symbol\")\n",
    "fee_info_okex = pd.concat([fee_info_okex, fee_info_okex.uly.apply(okex_get_single_margin)], axis=1)\n",
    "fee_info_okex = fee_info_okex[[\"maint_margin\", \"init_margin\"]]\n",
    "fee_info_okex = fee_info_okex.assign(fee_pct=0.0005, fee_fixed=0)\n",
    "fee_info_okex\n",
    "\n",
    "\n",
    "# Join with instrument_data\n",
    "DEFAULT_INIT_MARGIN = 0\n",
    "DEFAULT_MAINT_MARGIN = 0.15\n",
    "all_fee_info = pd.concat(\n",
    "    [\n",
    "        fee_info_binance,\n",
    "        fee_info_bitmex,\n",
    "        fee_info_bybit,\n",
    "        fee_info_gateio,\n",
    "        fee_info_kucoin,\n",
    "        fee_info_okex,\n",
    "    ],\n",
    "    keys=[\"binance\", \"bitmex\", \"bybit\", \"gateio\", \"kucoin\", \"okex\"],\n",
    "    names=[\"exchange\"],\n",
    ")\n",
    "\n",
    "all_fee_info = (\n",
    "    all_fee_info.astype(float)\n",
    "    .groupby(\"symbol\")\n",
    "    .apply(lambda c: c.fillna(c.mean()))\n",
    "    .fillna({\"init_margin\": DEFAULT_INIT_MARGIN, \"maint_margin\": DEFAULT_MAINT_MARGIN})\n",
    ")\n",
    "\n",
    "instrument_data = instrument_data.join(all_fee_info).reorder_levels(instrument_data.index.names)\n",
    "\n",
    "instrument_data_crossed = (\n",
    "    instrument_data.reset_index()\n",
    "    .merge(instrument_data.reset_index(), how=\"cross\", suffixes=(\"_a\", \"_b\"))\n",
    "    .pipe(\n",
    "        lambda df: df[\n",
    "            (df.exchange_a < df.exchange_b) & (df.inst_type_a <= df.inst_type_b) & (df.symbol_a == df.symbol_b)\n",
    "        ]\n",
    "    )\n",
    "    .drop(columns=\"symbol_b\")\n",
    "    .rename(columns={\"symbol_a\": \"symbol\"})\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# TODO: parallelize me\n",
    "spreads = pd.DataFrame(\n",
    "    index=pd.MultiIndex.from_arrays(\n",
    "        [[], [], [], [], []], names=[\"exchange_a\", \"exchange_b\", \"inst_type_a\", \"inst_type_b\", \"symbol\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "for idx, row in instrument_data_crossed.iterrows():\n",
    "    indexer_a = (row.exchange_a, row.inst_type_a, row.symbol)\n",
    "    indexer_b = (row.exchange_b, row.inst_type_b, row.symbol)\n",
    "    indexer = (row.exchange_a, row.exchange_b, row.inst_type_a, row.inst_type_b, row.symbol)\n",
    "    spread = Spread.from_ohlcv(pickle.loads(row.ohlcv_a), pickle.loads(row.ohlcv_b))\n",
    "\n",
    "    # bid_ask_a = pickle.loads(bid_ask_spreads.at[indexer_a, \"bid_ask_spread\"])\n",
    "    # bid_ask_b = pickle.loads(bid_ask_spreads.at[indexer_b, \"bid_ask_spread\"])\n",
    "    # fr_a = pickle.loads(funding_rates.at[indexer_a, \"funding_rate\"])\n",
    "    # fr_b = pickle.loads(funding_rates.at[indexer_b, \"funding_rate\"])\n",
    "\n",
    "    # spread.add_bid_ask_spread(bid_ask_a, bid_ask_b)\n",
    "    # spread.add_funding_rate(fr_a, fr_b)\n",
    "\n",
    "    spreads.at[indexer, \"spread\"] = pickle.dumps(spread)\n",
    "    spreads.at[\n",
    "        indexer, \"alias\"\n",
    "    ] = f\"{row.exchange_a[:4]}_{row.exchange_b[:4]}_{row.inst_type_a[:4]}_{row.inst_type_b[:4]}_{row.symbol}\"\n",
    "    spreads.at[indexer, \"volatility\"] = spread.volatility()\n",
    "    # spreads.at[indexer, (f\"avg_ba_spread_{s}\" for s in (\"a\", \"b\"))] = set(\n",
    "    #     x.bid_ask_spread.mean() for x in (bid_ask_a, bid_ask_b)\n",
    "    # )\n",
    "    spreads.at[indexer, \"earliest_time\"] = spread.earliest_time\n",
    "    spreads.at[indexer, \"latest_time\"] = spread.latest_time\n",
    "    spreads.at[indexer, \"valid_rows\"] = len(spread.valid_rows)\n",
    "    spreads.at[indexer, \"missing_rows\"] = len(spread.missing_rows)\n",
    "    spreads.at[indexer, \"gaps\"] = spread.gaps\n",
    "\n",
    "    fee_info_keys = [\"init_margin\", \"maint_margin\", \"fee_pct\", \"fee_fixed\"]\n",
    "    for key in [\"a\", \"b\"]:\n",
    "        spreads.at[indexer, f\"fee_info_{key}\"] = pickle.dumps({k: getattr(row, f\"{k}_{key}\") for k in fee_info_keys})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BacktestResult:\n",
    "    def __init__(self, portfolio: vbt.Portfolio, feed: Spread):\n",
    "        self.portfolio = portfolio\n",
    "        self.feed = feed\n",
    "\n",
    "    def slippage(self) -> pd.DataFrame:\n",
    "        \"\"\"Return slippage paid by day.\n",
    "        \n",
    "        Returns dataframe with datetime index and columns [exchange_0, exchange_1]\n",
    "        \"\"\"\n",
    "        close_prices = self.feed.underlying_col(\"close\").droplevel(1, axis=1).rename(columns=lambda c: c.split(\".\")[1])\n",
    "        filled_prices = (\n",
    "            self.portfolio.orders.records_readable.groupby([\"Timestamp\", \"Column\"])\n",
    "            .first()\n",
    "            .Price.unstack()\n",
    "            .rename(columns=lambda c: c.split(\".\")[1])\n",
    "        )\n",
    "        sizes = (\n",
    "            self.portfolio.orders.records_readable.groupby([\"Timestamp\", \"Column\"])\n",
    "            .sum()\n",
    "            .Size.unstack(\"Column\")\n",
    "            .rename(columns=lambda c: c.split(\".\")[1])\n",
    "        )\n",
    "        return abs(close_prices - filled_prices) * sizes\n",
    "\n",
    "    def plot(self) -> go.FigureWidget:\n",
    "        \"\"\"Return FigureWidget with plots for Spread, Zscore, Price, PnL, Returns, Slippage\"\"\"\n",
    "        portfolio = self.portfolio\n",
    "        feed = self.feed\n",
    "\n",
    "        df = portfolio.trades.records.sort_values([\"entry_idx\", \"col\"])\n",
    "        # For column 0, a short means we are long on the spread and vice versa\n",
    "        df = df[df.col == 0]\n",
    "\n",
    "        # direction 1 = short\n",
    "        # direction 0 = long\n",
    "        long_trades = df[df.direction == 1]\n",
    "        short_trades = df[df.direction == 0]\n",
    "\n",
    "        temp_signals = np.zeros(len(feed))\n",
    "        temp_signals[long_trades.entry_idx] = True\n",
    "        long_entries = pd.Series(index=feed[feed.time_column], data=temp_signals).astype(bool)\n",
    "\n",
    "        temp_signals = np.zeros(len(feed))\n",
    "        temp_signals[long_trades.exit_idx] = True\n",
    "        long_exits = pd.Series(index=feed[feed.time_column], data=temp_signals).astype(bool)\n",
    "\n",
    "        temp_signals = np.zeros(len(feed))\n",
    "        temp_signals[short_trades.entry_idx] = True\n",
    "        short_entries = pd.Series(index=feed[feed.time_column], data=temp_signals).astype(bool)\n",
    "\n",
    "        temp_signals = np.zeros(len(feed))\n",
    "        temp_signals[short_trades.exit_idx] = True\n",
    "        short_exits = pd.Series(index=feed[feed.time_column], data=temp_signals).astype(bool)\n",
    "\n",
    "        fig = vbt.make_subplots(rows=8, cols=1, shared_xaxes=True, vertical_spacing=0.05)\n",
    "        spread = feed.set_index(feed.time_column).close\n",
    "        zscore = feed.zscore()\n",
    "\n",
    "        spread.vbt.plot(add_trace_kwargs=dict(row=1, col=1), fig=fig, title=feed._underlying_info)\n",
    "        zscore.vbt.plot(add_trace_kwargs=dict(row=2, col=1), fig=fig)\n",
    "\n",
    "        # Plot entry and exit markers on z-score\n",
    "        short_entries.vbt.signals.plot_as_exit_markers(\n",
    "            zscore,\n",
    "            add_trace_kwargs=dict(row=2, col=1),\n",
    "            trace_kwargs=dict(marker=dict(opacity=0.4, size=12, color=\"green\"), name=\"short_entry\"),\n",
    "            fig=fig,\n",
    "        )\n",
    "        short_exits.vbt.signals.plot_as_entry_markers(\n",
    "            zscore,\n",
    "            add_trace_kwargs=dict(row=2, col=1),\n",
    "            trace_kwargs=dict(marker=dict(opacity=0.4, size=12, color=\"red\"), name=\"short_exit\"),\n",
    "            fig=fig,\n",
    "        )\n",
    "        long_entries.vbt.signals.plot_as_entry_markers(\n",
    "            zscore,\n",
    "            add_trace_kwargs=dict(row=2, col=1),\n",
    "            trace_kwargs=dict(marker=dict(opacity=0.8), name=\"long_entry\"),\n",
    "            fig=fig,\n",
    "        )\n",
    "        long_exits.vbt.signals.plot_as_exit_markers(\n",
    "            zscore,\n",
    "            add_trace_kwargs=dict(row=2, col=1),\n",
    "            trace_kwargs=dict(marker=dict(opacity=0.8), name=\"long_exit\"),\n",
    "            fig=fig,\n",
    "        )\n",
    "\n",
    "        # Plot individual close prices\n",
    "        feed.underlying_col(\"close\").droplevel(1, axis=1).rename(\n",
    "            columns=lambda c: c.split(\".\")[1] + \" close price\"\n",
    "        ).vbt.plot(add_trace_kwargs=dict(row=3, col=1), fig=fig)\n",
    "\n",
    "        # Plot daily returns\n",
    "        (portfolio.returns() * 100).rename(\"% returns\").vbt.scatterplot(add_trace_kwargs=dict(row=4, col=1), fig=fig)\n",
    "\n",
    "        # Plot order entry and exit prices\n",
    "        orders = portfolio.orders.records_readable\n",
    "        if len(orders) > 0:\n",
    "            orders[\"Side\"] = orders[\"Side\"].replace({\"Sell\": -1, \"Buy\": 1})\n",
    "            orders[\"Price\"] = orders[\"Price\"] * orders[\"Side\"]\n",
    "            orders[\"When\"] = pd.concat(\n",
    "                [pd.Series([\"entry\", \"exit\"]).repeat(2)] * int(np.ceil(len(orders) / 4)), ignore_index=True\n",
    "            ).values[: len(orders)]\n",
    "            orders = orders.set_index([\"Timestamp\", \"Column\", \"When\"])\n",
    "            orders = orders.unstack([\"Column\", \"When\"]).Price.rename(\n",
    "                columns=lambda c: c.split(\".\")[1] + \" fill price\", level=0\n",
    "            )\n",
    "            orders.vbt.scatterplot(add_trace_kwargs=dict(row=5, col=1), fig=fig)\n",
    "\n",
    "        # Plot daily PnL\n",
    "        self.portfolio.trades.records_readable.sort_values(\"Entry Timestamp\").groupby(\n",
    "            \"Entry Timestamp\"\n",
    "        ).PnL.sum().reindex(self.feed.open_time).fillna(0).rename(\"PnL\").vbt.scatterplot(\n",
    "            add_trace_kwargs=dict(row=6, col=1), fig=fig\n",
    "        )\n",
    "\n",
    "        # Plot cumulative returns\n",
    "        (portfolio.cumulative_returns() * 100).rename(\"cumulative returns\").vbt.plot(\n",
    "            add_trace_kwargs=dict(row=7, col=1), fig=fig\n",
    "        )\n",
    "\n",
    "        # Plot slippage\n",
    "        self.slippage().vbt.scatterplot(add_trace_kwargs=dict(row=8, col=1), fig=fig)\n",
    "\n",
    "        fig.update_layout(height=1200, width=1800, hovermode=\"x unified\", hoverlabel={\"namelength\": -1}, legend=None)\n",
    "        fig.add_shape(\n",
    "            type=\"rect\",\n",
    "            xref=\"paper\",\n",
    "            yref=\"y2\",\n",
    "            x0=0,\n",
    "            y0=1,\n",
    "            x1=1,\n",
    "            y1=-1,\n",
    "            fillcolor=\"gray\",\n",
    "            opacity=0.2,\n",
    "            layer=\"below\",\n",
    "            line_width=0,\n",
    "        )\n",
    "\n",
    "        return fig\n",
    "\n",
    "    def analyze(self):\n",
    "        \"\"\"Display plots, session stats, trades, orders, underlying prices\"\"\"\n",
    "        display(self.plot())\n",
    "        display(f\"slippage: {self.slippage().sum().sum()}\")\n",
    "        display(self.aggregate_stats())\n",
    "        display(self.portfolio.stats())\n",
    "        display(self.portfolio.trades.records_readable.sort_values(\"Entry Timestamp\").head(10))\n",
    "        display(self.portfolio.orders.records_readable.sort_values(\"Timestamp\").head(20))\n",
    "        display(self.feed.underlyings)\n",
    "\n",
    "    def get_leg_trades(self) -> pd.DataFrame:\n",
    "        \"\"\"Return DataFrame with additional stats per leg for each trade\"\"\"\n",
    "        portfolio = self.portfolio\n",
    "        orders = portfolio.orders.records_readable.sort_values(\"Timestamp\")\n",
    "        orders[\"col\"] = portfolio.orders.records.sort_values(\"idx\").col\n",
    "        try:\n",
    "            orders[\"When\"] = pd.concat([pd.Series([\"entry\", \"exit\"]).repeat(2)] * int(np.ceil(len(orders) / 4)), ignore_index=True).values[: len(orders)]\n",
    "        except ValueError:\n",
    "            orders[\"When\"] = pd.Series()\n",
    "        orders = orders.rename(columns={\"Price\": \"filled_price\", \"Size\": \"size\"})\n",
    "\n",
    "        close_prices = self.feed.underlying_col(\"close\").droplevel(1, axis=1).set_axis([0, 1], axis=1).melt(var_name=\"col\", value_name=\"close\", ignore_index=False).reset_index().rename(columns={\"open_time\": \"Timestamp\"})\n",
    "        slippage = orders.merge(close_prices)\n",
    "\n",
    "        slippage[\"slippage\"] = abs(slippage[\"close\"] - slippage[\"filled_price\"]) * slippage[\"size\"]\n",
    "        slippage = slippage[[\"Timestamp\", \"col\", \"slippage\", \"When\"]]\n",
    "        entry_slippage = slippage[slippage.When == \"entry\"].rename(columns={\"slippage\": \"entry_slippage\", \"Timestamp\": \"Entry Timestamp\"}).drop(columns=\"When\")\n",
    "        exit_slippage = slippage[slippage.When == \"exit\"].rename(columns={\"slippage\": \"exit_slippage\", \"Timestamp\": \"Exit Timestamp\"}).drop(columns=\"When\")\n",
    "\n",
    "        leg_trades = portfolio.trades.records_readable.sort_values(\"Entry Timestamp\")\n",
    "        leg_trades[\"col\"] = portfolio.trades.records.sort_values(\"entry_idx\").col\n",
    "        leg_trades = leg_trades.merge(self.feed.zscore(period=self.feed.zscore_period).rename(\"entry_zscore\"), left_on=\"Entry Timestamp\", right_index=True)\n",
    "        leg_trades = leg_trades.merge(self.feed.zscore(period=self.feed.zscore_period).rename(\"exit_zscore\"), left_on=\"Exit Timestamp\", right_index=True)\n",
    "        leg_trades = leg_trades.merge(portfolio.cash().rename(\"entry_cash\"), left_on=\"Entry Timestamp\", right_index=True)\n",
    "        leg_trades = leg_trades.merge(portfolio.cash().rename(\"exit_cash\"), left_on=\"Exit Timestamp\", right_index=True)\n",
    "        leg_trades = leg_trades.merge(entry_slippage)\n",
    "        leg_trades = leg_trades.merge(exit_slippage, how=\"left\") # Left merge because last trade may not be closed\n",
    "        leg_trades = leg_trades.merge(close_prices.rename(columns={\"Timestamp\": \"Entry Timestamp\"})).rename(columns={\"close\": \"entry_price\"})\n",
    "        leg_trades = leg_trades.merge(close_prices.rename(columns={\"Timestamp\": \"Exit Timestamp\"})).rename(columns={\"close\": \"exit_price\"})\n",
    "\n",
    "        leg_trades[\"slippage\"] = leg_trades[\"entry_slippage\"] + leg_trades[\"exit_slippage\"]\n",
    "        leg_trades[\"fees\"] = leg_trades[\"Entry Fees\"] + leg_trades[\"Exit Fees\"]\n",
    "        leg_trades.rename(columns={\"PnL\": \"PnL w fees\"}, inplace=True)\n",
    "        leg_trades[\"raw PnL\"] = leg_trades[\"PnL w fees\"] + leg_trades[\"fees\"]\n",
    "        leg_trades[\"PnL w slip\"] = leg_trades[\"raw PnL\"] - leg_trades[\"slippage\"]\n",
    "        leg_trades[\"PnL w slip + fees\"] = leg_trades[\"PnL w fees\"] - leg_trades[\"slippage\"]\n",
    "        \n",
    "        return leg_trades\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def group_trades(g: pd.DataFrame, sum_legs=False) -> pd.DataFrame:\n",
    "        \"\"\"Apply method for aggregating leg trades grouped by Entry Timestamp\"\"\"\n",
    "        out = pd.DataFrame()\n",
    "        entry_time = g[\"Entry Timestamp\"].iloc[0]\n",
    "        exit_time = g[\"Exit Timestamp\"].iloc[0]\n",
    "        names = g.Column.to_list()\n",
    "        status = g.Status.to_list()\n",
    "        directions = g.Direction.replace(\"Short\", -1).replace(\"Long\", 1).to_list()\n",
    "        spread_dir = 1 if directions[0] == -1 else -1\n",
    "        \n",
    "        if (g.Status == \"Closed\").all():\n",
    "            overall_status = \"Closed\"\n",
    "        elif (g.Status == \"Open\").any():\n",
    "            overall_status = \"Open\"\n",
    "        elif (g.status == \"Rejected\").any():\n",
    "            overall_status = \"Rejected\"\n",
    "        else:\n",
    "            overall_status = f\"{g.Status.iloc[0]} / {g.Status.iloc[1]}\"\n",
    "\n",
    "        entry_fees = g[\"Entry Fees\"].to_list()\n",
    "        exit_fees = g[\"Exit Fees\"].to_list()\n",
    "        total_fees = (g[\"Entry Fees\"] + g[\"Exit Fees\"]).to_list()\n",
    "\n",
    "        entry_slippage = g[\"entry_slippage\"].to_list()\n",
    "        exit_slippage = g[\"exit_slippage\"].to_list()\n",
    "        total_slippage = (g[\"entry_slippage\"] + g[\"exit_slippage\"]).to_list()\n",
    "\n",
    "        raw_pnl = g[\"raw PnL\"].to_list()\n",
    "        pnl_w_fees = g[\"PnL w fees\"].to_list()\n",
    "        pnl_w_slip = g[\"PnL w slip\"].to_list()\n",
    "        pnl_w_slip_fees = g[\"PnL w slip + fees\"].to_list()\n",
    "\n",
    "        entry_prices = g[\"entry_price\"].to_list()\n",
    "        exit_prices = g[\"exit_price\"].to_list()\n",
    "        entry_zscore = g[\"entry_zscore\"].iloc[0]\n",
    "        exit_zscore = g[\"exit_zscore\"].iloc[0]\n",
    "        filled_entry_prices = g[\"Avg Entry Price\"].to_list()\n",
    "        filled_exit_prices = g[\"Avg Exit Price\"].to_list()\n",
    "        sizes = g[\"Size\"].to_list()\n",
    "        entry_spread = entry_prices[1] - entry_prices[0]\n",
    "        exit_spread = exit_prices[1] - exit_prices[0]\n",
    "        filled_entry_spread = filled_entry_prices[1] - filled_entry_prices[0]\n",
    "        filled_exit_spread = filled_exit_prices[1] - filled_exit_prices[0]\n",
    "        \n",
    "        spread_change = (exit_spread - entry_spread) * spread_dir\n",
    "        filled_spread_change = (filled_exit_spread - filled_entry_spread) * spread_dir\n",
    "\n",
    "        start_cash = g[\"entry_cash\"].iloc[0] + sum(entry_fees) + sum(entry_slippage)\n",
    "        end_cash = g[\"exit_cash\"].iloc[0]\n",
    "\n",
    "        def add_wide_column(df: pd.DataFrame, name: str, values: list):\n",
    "            if sum_legs:\n",
    "                try:\n",
    "                    return df.assign(**{name: sum(values)})\n",
    "                except TypeError:\n",
    "                    pass\n",
    "            return df.assign(**{name: [values]})\n",
    "\n",
    "        out = add_wide_column(out, \"names\", names)\n",
    "        out = add_wide_column(out, \"status\", status)\n",
    "        out = add_wide_column(out, \"directions\", directions)\n",
    "        out = add_wide_column(out, \"entry_fees\", entry_fees)\n",
    "        out = add_wide_column(out, \"exit_fees\", exit_fees)\n",
    "        out = add_wide_column(out, \"total_fees\", total_fees)\n",
    "        out = add_wide_column(out, \"entry_slippage\", entry_slippage)\n",
    "        out = add_wide_column(out, \"exit_slippage\", exit_slippage)\n",
    "        out = add_wide_column(out, \"total_slippage\", total_slippage)\n",
    "        out = add_wide_column(out, \"raw_pnl\", raw_pnl)\n",
    "        out = add_wide_column(out, \"pnl_w_fees\", pnl_w_fees)\n",
    "        out = add_wide_column(out, \"pnl_w_slip\", pnl_w_slip)\n",
    "        out = add_wide_column(out, \"pnl_w_slip_fees\", pnl_w_slip_fees)\n",
    "        out = add_wide_column(out, \"entry_prices\", entry_prices)\n",
    "        out = add_wide_column(out, \"exit_prices\", exit_prices)\n",
    "        out = add_wide_column(out, \"filled_entry_prices\", filled_entry_prices)\n",
    "        out = add_wide_column(out, \"filled_exit_prices\", filled_exit_prices)\n",
    "        out = add_wide_column(out, \"sizes\", sizes)\n",
    "\n",
    "        out[\"entry_time\"] = entry_time\n",
    "        out[\"exit_time\"] = exit_time\n",
    "        out[\"entry_zscore\"] = entry_zscore\n",
    "        out[\"exit_zscore\"] = exit_zscore\n",
    "        out[\"spread_dir\"] = spread_dir\n",
    "        out[\"overall_status\"] = overall_status\n",
    "        out[\"entry_spread\"] = entry_spread\n",
    "        out[\"exit_spread\"] = exit_spread\n",
    "        out[\"filled_entry_spread\"] = filled_entry_spread\n",
    "        out[\"filled_exit_spread\"] = filled_exit_spread\n",
    "        out[\"spread_change\"] = spread_change\n",
    "        out[\"filled_spread_change\"] = filled_spread_change\n",
    "        out[\"start_cash\"] = start_cash\n",
    "        out[\"end_cash\"] = end_cash\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def format_trade(t: pd.Series) -> str:\n",
    "        \"\"\"Format trade string using an aggregated trade created by `self.group_trades`\"\"\"\n",
    "        exchanges = [x.split(\".\")[1] for x in t.names]\n",
    "        symbol = t.names[0].split(\".\")[-1]\n",
    "        starttime = t.entry_time.strftime(\"%Y-%m-%d\")\n",
    "        endtime = t.exit_time.strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        # Rounding factors\n",
    "        spread_rf = 4 if (abs(t.entry_spread) < 1) else 2\n",
    "        price_rf = 4 if (sum([abs(x) for x in t.entry_prices]) / len(t.entry_prices)) < 1 else 2\n",
    "        size_rf = 3 if (sum(t.sizes) / len(t.sizes)) < 1 else 2\n",
    "        \n",
    "        # direction symbols\n",
    "        d_sym = {-1: \"\\\\\", 1: \"/\"}\n",
    "        \n",
    "        # direction strings\n",
    "        d_str = {-1: \"Short\", 1: \"Long\"}\n",
    "        \n",
    "        entry_spread = t.entry_spread\n",
    "        filled_entry_spread = t.filled_entry_spread\n",
    "        entry_prices = [(x) for x in t.entry_prices]\n",
    "        filled_entry_prices = [(x) for x in t.filled_entry_prices]\n",
    "        \n",
    "        entry_zscore = t.entry_zscore\n",
    "        exit_zscore = t.exit_zscore\n",
    "        \n",
    "        exit_spread = t.exit_spread\n",
    "        filled_exit_spread = t.filled_exit_spread\n",
    "        exit_prices = [(x) for x in t.exit_prices]\n",
    "        filled_exit_prices = [(x) for x in t.filled_exit_prices]\n",
    "        \n",
    "        spread_change = t.spread_change\n",
    "        spread_change_pct = (100 * spread_change / abs(entry_spread))\n",
    "        filled_spread_change = t.filled_spread_change\n",
    "        filled_spread_change_pct = (100 * filled_spread_change / abs(filled_entry_spread))\n",
    "        \n",
    "        trade_value = (sum(size * price for size, price in zip(t.sizes, t.entry_prices)))\n",
    "        sizes = [(x) for x in t.sizes]\n",
    "        raw_pnl = (sum(t.raw_pnl))\n",
    "        raw_returns = 100 * sum(t.raw_pnl) / trade_value\n",
    "        pnl_w_slip_fees = sum(t.pnl_w_slip_fees)\n",
    "        returns_w_slip_fees = 100 * sum(t.pnl_w_slip_fees) / trade_value\n",
    "        \n",
    "        slippage = sum(t.entry_slippage) + sum(t.exit_slippage)\n",
    "        slippage_pct = 100 * slippage / trade_value\n",
    "        entry_slippage = sum(t.entry_slippage)\n",
    "        exit_slippage = sum(t.exit_slippage)\n",
    "        \n",
    "        fees = sum(t.total_fees)\n",
    "        fee_pct = 100 * fees / trade_value\n",
    "        entry_fees = sum(t.entry_fees)\n",
    "        exit_fees = sum(t.exit_fees)\n",
    "        \n",
    "        formatter = util.BashFormatter()\n",
    "        def add_color(x: str, x_float: float):\n",
    "            if x_float > 0:\n",
    "                return formatter.format(x, \"green\", \"black\", \"bold\")\n",
    "            elif x_float < 0:\n",
    "                return formatter.format(x, \"red\", \"black\", \"bold\")\n",
    "            else:\n",
    "                return formatter.format(x, \"orange\", \"black\", \"bold\")\n",
    "\n",
    "        def add_secondary_color(x: str, x_float: float):\n",
    "            if x_float > 0:\n",
    "                return formatter.color(x, \"light_green\")\n",
    "            elif x_float < 0:\n",
    "                return formatter.color(x, \"light_red\")\n",
    "            else:\n",
    "                return formatter.color(x, \"light_orange\")\n",
    "            \n",
    "        margin = 25\n",
    "        trade_info = \\\n",
    "        f\"\"\"\n",
    "        {'-'*130}\n",
    "        {'Info:':{margin}} {d_str[t.spread_dir]} {d_sym[t.spread_dir]} | {symbol} | ({exchanges[1]} - {exchanges[0]}) | {t.overall_status} | {starttime} --> {endtime} ({(t.exit_time - t.entry_time).days} days)\n",
    "        {'Cash:':{margin}} {f'Start[ {t.start_cash:7.2f}]':20} End[ {t.end_cash:7.2f}]\n",
    "        {'Entry Spread:':{margin}} {f'Inital[ {entry_spread: .{spread_rf}f} ({entry_prices[1]: .{spread_rf}f} - {entry_prices[0]: .{spread_rf}f})]':40} Filled[ {filled_entry_spread: .{spread_rf}f} ({filled_entry_prices[1]: .{spread_rf}f} - {filled_entry_prices[0]: .{spread_rf}f})]\n",
    "        {'Exit Spread:':{margin}} {f'Inital[ {exit_spread: .{spread_rf}f} ({exit_prices[1]: .{spread_rf}f} - {exit_prices[0]: .{spread_rf}f})]':40} Filled[ {filled_exit_spread: .{spread_rf}f} ({filled_exit_prices[1]: .{spread_rf}f} - {filled_exit_prices[0]: .{spread_rf}f})]\n",
    "        {'Spread change:':{margin}} {add_secondary_color(f'Inital[ {spread_change: .{spread_rf}f} ({spread_change_pct:.2f}%)]', spread_change):40} {add_secondary_color(f'Filled[ {filled_spread_change:.{spread_rf}f} ({filled_spread_change_pct:.2f}%)]', filled_spread_change)}\n",
    "        {'Trade Value:':{margin}} {trade_value:.2f} ({sizes[0]:.{size_rf}f}x{filled_entry_prices[0]:.{price_rf}f} + {sizes[1]:.{size_rf}f}x{filled_entry_prices[1]:.{price_rf}f})\n",
    "        {'Raw PnL:':{margin}} {add_secondary_color(f'{raw_pnl:8.2f} ({raw_returns: .2f}%)', raw_pnl)}\n",
    "        {'PnL (w/ slip & fees):':{margin}} {add_color(f'{pnl_w_slip_fees:8.2f} ({returns_w_slip_fees: .2f}%)', pnl_w_slip_fees)}\n",
    "        {'Z Score:':{margin}} {f'Entry[ {entry_zscore:7.2f}]':20} Exit[ {exit_zscore:7.2f}]\n",
    "        {'Slippage:':{margin}} {slippage:8.2f} ({slippage_pct:.2f}%) {f'Entry[ {entry_slippage:7.2f}]':20} Exit[ {exit_slippage:7.2f}]\n",
    "        {'Fees:':{margin}} {fees:8.2f} ({fee_pct:.2f}%) {f'Entry[ {entry_fees:7.2f}]':20} Exit[ {exit_fees:7.2f}]\n",
    "        \n",
    "        {'Exchange:':{margin}} {exchanges[0]:>10}   {exchanges[1]:>10}\n",
    "        {'Entry Price: ':{margin}} {f'{entry_prices[0]:.{price_rf}f}':>10}   {f'{entry_prices[1]:.{price_rf}f}':>10}\n",
    "        {'Entry Price (filled): ':{margin}} {f'{filled_entry_prices[0]:.{price_rf}f}':>10}   {f'{filled_entry_prices[1]:.{price_rf}f}':>10}\n",
    "        {'Exit Price: ':{margin}} {f'{exit_prices[0]:.{price_rf}f}':>10}   {f'{exit_prices[1]:.{price_rf}f}':>10}\n",
    "        {'Exit Price (filled): ':{margin}} {f'{filled_exit_prices[0]:.{price_rf}f}':>10}   {f'{filled_exit_prices[1]:.{price_rf}f}':>10}\n",
    "        {'Trade Size: ':{margin}} {f'{sizes[0]:.{size_rf}f}':>10}   {f'{sizes[1]:.{size_rf}f}':>10}\n",
    "        {'Trade Value: ':{margin}} {f'{sizes[0] * filled_entry_prices[0]:.{price_rf}f}':>10}   {f'{sizes[1] * filled_entry_prices[1]:.{price_rf}f}':>10}\n",
    "        {'Raw PnL: ':{margin}} {add_secondary_color(f'{t.raw_pnl[0]:.2f}', t.raw_pnl[0]):>10}   {add_secondary_color(f'{t.raw_pnl[1]:.2f}', t.raw_pnl[1]):>10}\n",
    "        {'slippage: ':{margin}} {f'{t.entry_slippage[0] + t.exit_slippage[0]:.2f}':>10}   {f'{t.entry_slippage[1] + t.exit_slippage[1]:.2f}':>10}\n",
    "        {'fees:':{margin}} {f'{t.total_fees[0]:.2f}':>10}   {f'{t.total_fees[1]:.2f}':>10}\n",
    "        {'PnL (w/ slip only):':{margin}} {f'{t.pnl_w_slip[0]:.2f}':>10}   {f'{t.pnl_w_slip[1]:.2f}':>10}\n",
    "        {'PnL (w/ fees only):':{margin}} {f'{t.pnl_w_fees[0]:.2f}':>10}   {f'{t.pnl_w_fees[1]:.2f}':>10}\n",
    "        {'PnL (w/ slip & fees):':{margin}} {f'{t.pnl_w_slip_fees[0]:.2f}':>10}   {f'{t.pnl_w_slip_fees[1]:.2f}':>10}\n",
    "        {'-'*130}\n",
    "        \"\"\"\n",
    "\n",
    "        return trade_info\n",
    "\n",
    "\n",
    "    def print_all_trades(self):\n",
    "        \"\"\"Print formatted trades to stdout\"\"\"\n",
    "        leg_trades = self.get_leg_trades()\n",
    "        if len(leg_trades) == 0:\n",
    "            print(\"No trades to show\")\n",
    "        else:\n",
    "            grouped_trades = leg_trades.sort_values([\"Entry Timestamp\", \"col\"]).groupby(\"Entry Timestamp\", as_index=False).apply(self.group_trades).reset_index(level=1, drop=True)\n",
    "            for idx, trade in grouped_trades.iterrows():\n",
    "                print(self.format_trade(trade))\n",
    "                        \n",
    "\n",
    "    def aggregate_stats(self):\n",
    "        stats = pd.Series()\n",
    "        leg_trades = self.get_leg_trades()\n",
    "        if len(leg_trades) == 0:\n",
    "            stats[\"avg_fees\"] = np.nan\n",
    "            stats[\"avg_slippage\"] = np.nan\n",
    "            stats[\"avg_pnl\"] = np.nan\n",
    "            stats[\"profitable_trades\"] = 0\n",
    "            stats[\"losing_trades\"] = 0\n",
    "            stats[\"total_trades\"] = 0\n",
    "            return stats\n",
    "            \n",
    "        grouped_trades = leg_trades.sort_values([\"Entry Timestamp\", \"col\"]).groupby(\"Entry Timestamp\", as_index=False).apply(self.group_trades, sum_legs=True).reset_index(level=1, drop=True)\n",
    "        stats[\"avg_fees\"] = grouped_trades[\"total_fees\"].mean()\n",
    "        stats[\"avg_slippage\"] = grouped_trades[\"total_slippage\"].mean()\n",
    "        stats[\"avg_pnl\"] = grouped_trades[\"pnl_w_slip_fees\"].mean()\n",
    "        stats[\"profitable_trades\"] = (grouped_trades[\"pnl_w_slip_fees\"] > 0).sum()\n",
    "        stats[\"losing_trades\"] = (grouped_trades[\"pnl_w_slip_fees\"] < 0).sum()\n",
    "        stats[\"total_trades\"] = len(grouped_trades[grouped_trades.overall_status == \"Closed\"])\n",
    "        return stats\n",
    "    \n",
    "class ChainedBacktestResult:\n",
    "    def __init__(self, portfolio: vbt.Portfolio, all_spreads: Spread):\n",
    "        self.portfolio = portfolio\n",
    "        self.all_spreads = all_spreads\n",
    "\n",
    "    # def slippage(self) -> pd.DataFrame:\n",
    "    #     \"\"\"Return slippage paid by day.\n",
    "\n",
    "    #     Returns dataframe with datetime index and columns [exchange_0, exchange_1]\n",
    "    #     \"\"\"\n",
    "    #     close_prices = self.feed.underlying_col(\"close\").droplevel(1, axis=1).rename(columns=lambda c: c.split(\".\")[1])\n",
    "    #     filled_prices = (\n",
    "    #         self.portfolio.orders.records_readable.groupby([\"Timestamp\", \"Column\"])\n",
    "    #         .first()\n",
    "    #         .Price.unstack()\n",
    "    #         .rename(columns=lambda c: c.split(\".\")[1])\n",
    "    #     )\n",
    "    #     sizes = (\n",
    "    #         self.portfolio.orders.records_readable.groupby([\"Timestamp\", \"Column\"])\n",
    "    #         .sum()\n",
    "    #         .Size.unstack(\"Column\")\n",
    "    #         .rename(columns=lambda c: c.split(\".\")[1])\n",
    "    #     )\n",
    "    #     return abs(close_prices - filled_prices) * sizes\n",
    "\n",
    "    def plot(self) -> go.FigureWidget:\n",
    "        \"\"\"Return FigureWidget with plots for Spread, Zscore, Price, PnL, Returns, Slippage\"\"\"\n",
    "        portfolio = self.portfolio\n",
    "        feed = self.feed\n",
    "\n",
    "        df = portfolio.trades.records.sort_values([\"entry_idx\", \"col\"])\n",
    "        # For column 0, a short means we are long on the spread and vice versa\n",
    "        df = df[df.col == 0]\n",
    "\n",
    "        # direction 1 = short\n",
    "        # direction 0 = long\n",
    "        long_trades = df[df.direction == 1]\n",
    "        short_trades = df[df.direction == 0]\n",
    "\n",
    "        temp_signals = np.zeros(len(feed))\n",
    "        temp_signals[long_trades.entry_idx] = True\n",
    "        long_entries = pd.Series(index=feed[feed.time_column], data=temp_signals).astype(bool)\n",
    "\n",
    "        temp_signals = np.zeros(len(feed))\n",
    "        temp_signals[long_trades.exit_idx] = True\n",
    "        long_exits = pd.Series(index=feed[feed.time_column], data=temp_signals).astype(bool)\n",
    "\n",
    "        temp_signals = np.zeros(len(feed))\n",
    "        temp_signals[short_trades.entry_idx] = True\n",
    "        short_entries = pd.Series(index=feed[feed.time_column], data=temp_signals).astype(bool)\n",
    "\n",
    "        temp_signals = np.zeros(len(feed))\n",
    "        temp_signals[short_trades.exit_idx] = True\n",
    "        short_exits = pd.Series(index=feed[feed.time_column], data=temp_signals).astype(bool)\n",
    "\n",
    "        fig = vbt.make_subplots(rows=8, cols=1, shared_xaxes=True, vertical_spacing=0.05)\n",
    "        spread = feed.set_index(feed.time_column).close\n",
    "        zscore = feed.zscore()\n",
    "\n",
    "        spread.vbt.plot(add_trace_kwargs=dict(row=1, col=1), fig=fig, title=feed._underlying_info)\n",
    "        zscore.vbt.plot(add_trace_kwargs=dict(row=2, col=1), fig=fig)\n",
    "\n",
    "        # Plot entry and exit markers on z-score\n",
    "        short_entries.vbt.signals.plot_as_exit_markers(\n",
    "            zscore,\n",
    "            add_trace_kwargs=dict(row=2, col=1),\n",
    "            trace_kwargs=dict(marker=dict(opacity=0.4, size=12, color=\"green\"), name=\"short_entry\"),\n",
    "            fig=fig,\n",
    "        )\n",
    "        short_exits.vbt.signals.plot_as_entry_markers(\n",
    "            zscore,\n",
    "            add_trace_kwargs=dict(row=2, col=1),\n",
    "            trace_kwargs=dict(marker=dict(opacity=0.4, size=12, color=\"red\"), name=\"short_exit\"),\n",
    "            fig=fig,\n",
    "        )\n",
    "        long_entries.vbt.signals.plot_as_entry_markers(\n",
    "            zscore,\n",
    "            add_trace_kwargs=dict(row=2, col=1),\n",
    "            trace_kwargs=dict(marker=dict(opacity=0.8), name=\"long_entry\"),\n",
    "            fig=fig,\n",
    "        )\n",
    "        long_exits.vbt.signals.plot_as_exit_markers(\n",
    "            zscore,\n",
    "            add_trace_kwargs=dict(row=2, col=1),\n",
    "            trace_kwargs=dict(marker=dict(opacity=0.8), name=\"long_exit\"),\n",
    "            fig=fig,\n",
    "        )\n",
    "\n",
    "        # Plot individual close prices\n",
    "        feed.underlying_col(\"close\").droplevel(1, axis=1).rename(\n",
    "            columns=lambda c: c.split(\".\")[1] + \" close price\"\n",
    "        ).vbt.plot(add_trace_kwargs=dict(row=3, col=1), fig=fig)\n",
    "\n",
    "        # Plot daily returns\n",
    "        (portfolio.returns() * 100).rename(\"% returns\").vbt.scatterplot(add_trace_kwargs=dict(row=4, col=1), fig=fig)\n",
    "\n",
    "        # Plot order entry and exit prices\n",
    "        orders = portfolio.orders.records_readable\n",
    "        if len(orders) > 0:\n",
    "            orders[\"Side\"] = orders[\"Side\"].replace({\"Sell\": -1, \"Buy\": 1})\n",
    "            orders[\"Price\"] = orders[\"Price\"] * orders[\"Side\"]\n",
    "            orders[\"When\"] = pd.concat(\n",
    "                [pd.Series([\"entry\", \"exit\"]).repeat(2)] * int(np.ceil(len(orders) / 4)), ignore_index=True\n",
    "            ).values[: len(orders)]\n",
    "            orders = orders.set_index([\"Timestamp\", \"Column\", \"When\"])\n",
    "            orders = orders.unstack([\"Column\", \"When\"]).Price.rename(\n",
    "                columns=lambda c: c.split(\".\")[1] + \" fill price\", level=0\n",
    "            )\n",
    "            orders.vbt.scatterplot(add_trace_kwargs=dict(row=5, col=1), fig=fig)\n",
    "\n",
    "        # Plot daily PnL\n",
    "        self.portfolio.trades.records_readable.sort_values(\"Entry Timestamp\").groupby(\n",
    "            \"Entry Timestamp\"\n",
    "        ).PnL.sum().reindex(self.feed.open_time).fillna(0).rename(\"PnL\").vbt.scatterplot(\n",
    "            add_trace_kwargs=dict(row=6, col=1), fig=fig\n",
    "        )\n",
    "\n",
    "        # Plot cumulative returns\n",
    "        (portfolio.cumulative_returns() * 100).rename(\"cumulative returns\").vbt.plot(\n",
    "            add_trace_kwargs=dict(row=7, col=1), fig=fig\n",
    "        )\n",
    "\n",
    "        # Plot slippage\n",
    "        self.slippage().vbt.scatterplot(add_trace_kwargs=dict(row=8, col=1), fig=fig)\n",
    "\n",
    "        fig.update_layout(height=1200, width=1800, hovermode=\"x unified\", hoverlabel={\"namelength\": -1}, legend=None)\n",
    "        fig.add_shape(\n",
    "            type=\"rect\",\n",
    "            xref=\"paper\",\n",
    "            yref=\"y2\",\n",
    "            x0=0,\n",
    "            y0=1,\n",
    "            x1=1,\n",
    "            y1=-1,\n",
    "            fillcolor=\"gray\",\n",
    "            opacity=0.2,\n",
    "            layer=\"below\",\n",
    "            line_width=0,\n",
    "        )\n",
    "\n",
    "        return fig\n",
    "\n",
    "    def analyze(self):\n",
    "        \"\"\"Display plots, session stats, trades, orders, underlying prices\"\"\"\n",
    "        display(self.plot())\n",
    "        display(f\"slippage: {self.slippage().sum().sum()}\")\n",
    "        display(self.aggregate_stats())\n",
    "        display(self.portfolio.stats())\n",
    "        display(self.portfolio.trades.records_readable.sort_values(\"Entry Timestamp\").head(10))\n",
    "        display(self.portfolio.orders.records_readable.sort_values(\"Timestamp\").head(20))\n",
    "        display(self.feed.underlyings)\n",
    "\n",
    "    def get_leg_trades(self) -> pd.DataFrame:\n",
    "        \"\"\"Return DataFrame with additional stats per leg for each trade\"\"\"\n",
    "        spreads = self.all_spreads\n",
    "        portfolio = self.portfolio\n",
    "        orders = portfolio.orders.records_readable.sort_values([\"Timestamp\", \"Order Id\"])\n",
    "        orders[\"col\"] = portfolio.orders.records.sort_values(\"idx\").col\n",
    "        try:\n",
    "            orders[\"When\"] = pd.concat(\n",
    "                [pd.Series([\"entry\", \"exit\"]).repeat(2)] * int(np.ceil(len(orders) / 4)), ignore_index=True\n",
    "            ).values[: len(orders)]\n",
    "        except ValueError:\n",
    "            orders[\"When\"] = pd.Series()\n",
    "        orders = orders.rename(columns={\"Price\": \"filled_price\", \"Size\": \"size\"})\n",
    "        orders\n",
    "        close_prices = pd.concat(\n",
    "            [\n",
    "                pickle.loads(spreads.iloc[i].spread)\n",
    "                .underlying_col(\"close\")\n",
    "                .droplevel(1, axis=1)\n",
    "                .set_axis([i, i + len(spreads)], axis=1)\n",
    "                .melt(var_name=\"col\", value_name=\"close\", ignore_index=False)\n",
    "                .reset_index()\n",
    "                .rename(columns={\"open_time\": \"Timestamp\"})\n",
    "                for i in range(len(spreads))\n",
    "            ],\n",
    "            axis=0,\n",
    "        )\n",
    "        zscores = pd.concat(\n",
    "            [\n",
    "                pickle.loads(spreads.iloc[i].spread).zscore(period=30).to_frame().assign(col=i)\n",
    "                for i in range(len(spreads))\n",
    "            ],\n",
    "            axis=0,\n",
    "        ).reset_index()\n",
    "        zscores = pd.concat([zscores, zscores.assign(col=zscores.col + zscores.col.nunique())], axis=0)\n",
    "        slippage = orders.merge(close_prices, left_on=[\"Timestamp\", \"col\"], right_on=[\"Timestamp\", \"col\"], how=\"left\")\n",
    "        slippage[\"slippage\"] = abs(slippage[\"close\"] - slippage[\"filled_price\"]) * slippage[\"size\"]\n",
    "        slippage = slippage[[\"Timestamp\", \"col\", \"slippage\", \"When\"]]\n",
    "        entry_slippage = (\n",
    "            slippage[slippage.When == \"entry\"]\n",
    "            .rename(columns={\"slippage\": \"entry_slippage\", \"Timestamp\": \"Entry Timestamp\"})\n",
    "            .drop(columns=\"When\")\n",
    "        )\n",
    "        exit_slippage = (\n",
    "            slippage[slippage.When == \"exit\"]\n",
    "            .rename(columns={\"slippage\": \"exit_slippage\", \"Timestamp\": \"Exit Timestamp\"})\n",
    "            .drop(columns=\"When\")\n",
    "        )\n",
    "        leg_trades = portfolio.trades.records_readable.sort_values(\"Entry Timestamp\")\n",
    "        leg_trades[\"col\"] = portfolio.trades.records.sort_values(\"entry_idx\").col\n",
    "        leg_trades = leg_trades.merge(\n",
    "            zscores.rename(columns={\"zscore\": \"entry_zscore\"}),\n",
    "            left_on=[\"Entry Timestamp\", \"col\"],\n",
    "            right_on=[\"open_time\", \"col\"],\n",
    "            how=\"left\",\n",
    "        ).drop(columns=\"open_time\")\n",
    "        leg_trades = leg_trades.merge(\n",
    "            zscores.rename(columns={\"zscore\": \"exit_zscore\"}),\n",
    "            left_on=[\"Exit Timestamp\", \"col\"],\n",
    "            right_on=[\"open_time\", \"col\"],\n",
    "            how=\"left\",\n",
    "        ).drop(columns=\"open_time\")\n",
    "\n",
    "        leg_trades = leg_trades.merge(\n",
    "            portfolio.cash().rename(\"entry_cash\"), left_on=\"Entry Timestamp\", right_index=True\n",
    "        )\n",
    "        leg_trades = leg_trades.merge(portfolio.cash().rename(\"exit_cash\"), left_on=\"Exit Timestamp\", right_index=True)\n",
    "        leg_trades = leg_trades.merge(entry_slippage)\n",
    "        leg_trades = leg_trades.merge(exit_slippage, how=\"left\")  # Left merge because last trade may not be closed\n",
    "        leg_trades = leg_trades.merge(close_prices.rename(columns={\"Timestamp\": \"Entry Timestamp\"})).rename(\n",
    "            columns={\"close\": \"entry_price\"}\n",
    "        )\n",
    "        leg_trades = leg_trades.merge(close_prices.rename(columns={\"Timestamp\": \"Exit Timestamp\"})).rename(\n",
    "            columns={\"close\": \"exit_price\"}\n",
    "        )\n",
    "        leg_trades[\"slippage\"] = leg_trades[\"entry_slippage\"] + leg_trades[\"exit_slippage\"]\n",
    "        leg_trades[\"fees\"] = leg_trades[\"Entry Fees\"] + leg_trades[\"Exit Fees\"]\n",
    "        leg_trades.rename(columns={\"PnL\": \"PnL w fees\"}, inplace=True)\n",
    "        leg_trades[\"raw PnL\"] = leg_trades[\"PnL w fees\"] + leg_trades[\"fees\"]\n",
    "        leg_trades[\"PnL w slip\"] = leg_trades[\"raw PnL\"] - leg_trades[\"slippage\"]\n",
    "        leg_trades[\"PnL w slip + fees\"] = leg_trades[\"PnL w fees\"] - leg_trades[\"slippage\"]\n",
    "\n",
    "        return leg_trades\n",
    "\n",
    "    @staticmethod\n",
    "    def group_trades(g: pd.DataFrame, sum_legs=False) -> pd.DataFrame:\n",
    "        \"\"\"Apply method for aggregating leg trades grouped by Entry Timestamp\"\"\"\n",
    "        out = pd.DataFrame()\n",
    "        entry_time = g[\"Entry Timestamp\"].iloc[0]\n",
    "        exit_time = g[\"Exit Timestamp\"].iloc[0]\n",
    "        names = g.Column.to_list()\n",
    "        status = g.Status.to_list()\n",
    "        directions = g.Direction.replace(\"Short\", -1).replace(\"Long\", 1).to_list()\n",
    "        spread_dir = 1 if directions[0] == -1 else -1\n",
    "\n",
    "        if (g.Status == \"Closed\").all():\n",
    "            overall_status = \"Closed\"\n",
    "        elif (g.Status == \"Open\").any():\n",
    "            overall_status = \"Open\"\n",
    "        elif (g.status == \"Rejected\").any():\n",
    "            overall_status = \"Rejected\"\n",
    "        else:\n",
    "            overall_status = f\"{g.Status.iloc[0]} / {g.Status.iloc[1]}\"\n",
    "\n",
    "        entry_fees = g[\"Entry Fees\"].to_list()\n",
    "        exit_fees = g[\"Exit Fees\"].to_list()\n",
    "        total_fees = (g[\"Entry Fees\"] + g[\"Exit Fees\"]).to_list()\n",
    "\n",
    "        entry_slippage = g[\"entry_slippage\"].to_list()\n",
    "        exit_slippage = g[\"exit_slippage\"].to_list()\n",
    "        total_slippage = (g[\"entry_slippage\"] + g[\"exit_slippage\"]).to_list()\n",
    "\n",
    "        raw_pnl = g[\"raw PnL\"].to_list()\n",
    "        pnl_w_fees = g[\"PnL w fees\"].to_list()\n",
    "        pnl_w_slip = g[\"PnL w slip\"].to_list()\n",
    "        pnl_w_slip_fees = g[\"PnL w slip + fees\"].to_list()\n",
    "\n",
    "        entry_prices = g[\"entry_price\"].to_list()\n",
    "        exit_prices = g[\"exit_price\"].to_list()\n",
    "        entry_zscore = g[\"entry_zscore\"].iloc[0]\n",
    "        exit_zscore = g[\"exit_zscore\"].iloc[0]\n",
    "        filled_entry_prices = g[\"Avg Entry Price\"].to_list()\n",
    "        filled_exit_prices = g[\"Avg Exit Price\"].to_list()\n",
    "        sizes = g[\"Size\"].to_list()\n",
    "        entry_spread = entry_prices[1] - entry_prices[0]\n",
    "        exit_spread = exit_prices[1] - exit_prices[0]\n",
    "        filled_entry_spread = filled_entry_prices[1] - filled_entry_prices[0]\n",
    "        filled_exit_spread = filled_exit_prices[1] - filled_exit_prices[0]\n",
    "\n",
    "        spread_change = (exit_spread - entry_spread) * spread_dir\n",
    "        filled_spread_change = (filled_exit_spread - filled_entry_spread) * spread_dir\n",
    "\n",
    "        start_cash = g[\"entry_cash\"].iloc[0] + sum(entry_fees) + sum(entry_slippage)\n",
    "        end_cash = g[\"exit_cash\"].iloc[0]\n",
    "\n",
    "        def add_wide_column(df: pd.DataFrame, name: str, values: list):\n",
    "            if sum_legs:\n",
    "                try:\n",
    "                    return df.assign(**{name: sum(values)})\n",
    "                except TypeError:\n",
    "                    pass\n",
    "            return df.assign(**{name: [values]})\n",
    "\n",
    "        out = add_wide_column(out, \"names\", names)\n",
    "        out = add_wide_column(out, \"status\", status)\n",
    "        out = add_wide_column(out, \"directions\", directions)\n",
    "        out = add_wide_column(out, \"entry_fees\", entry_fees)\n",
    "        out = add_wide_column(out, \"exit_fees\", exit_fees)\n",
    "        out = add_wide_column(out, \"total_fees\", total_fees)\n",
    "        out = add_wide_column(out, \"entry_slippage\", entry_slippage)\n",
    "        out = add_wide_column(out, \"exit_slippage\", exit_slippage)\n",
    "        out = add_wide_column(out, \"total_slippage\", total_slippage)\n",
    "        out = add_wide_column(out, \"raw_pnl\", raw_pnl)\n",
    "        out = add_wide_column(out, \"pnl_w_fees\", pnl_w_fees)\n",
    "        out = add_wide_column(out, \"pnl_w_slip\", pnl_w_slip)\n",
    "        out = add_wide_column(out, \"pnl_w_slip_fees\", pnl_w_slip_fees)\n",
    "        out = add_wide_column(out, \"entry_prices\", entry_prices)\n",
    "        out = add_wide_column(out, \"exit_prices\", exit_prices)\n",
    "        out = add_wide_column(out, \"filled_entry_prices\", filled_entry_prices)\n",
    "        out = add_wide_column(out, \"filled_exit_prices\", filled_exit_prices)\n",
    "        out = add_wide_column(out, \"sizes\", sizes)\n",
    "\n",
    "        out[\"entry_time\"] = entry_time\n",
    "        out[\"exit_time\"] = exit_time\n",
    "        out[\"entry_zscore\"] = entry_zscore\n",
    "        out[\"exit_zscore\"] = exit_zscore\n",
    "        out[\"spread_dir\"] = spread_dir\n",
    "        out[\"overall_status\"] = overall_status\n",
    "        out[\"entry_spread\"] = entry_spread\n",
    "        out[\"exit_spread\"] = exit_spread\n",
    "        out[\"filled_entry_spread\"] = filled_entry_spread\n",
    "        out[\"filled_exit_spread\"] = filled_exit_spread\n",
    "        out[\"spread_change\"] = spread_change\n",
    "        out[\"filled_spread_change\"] = filled_spread_change\n",
    "        out[\"start_cash\"] = start_cash\n",
    "        out[\"end_cash\"] = end_cash\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def format_trade(t: pd.Series) -> str:\n",
    "        \"\"\"Format trade string using an aggregated trade created by `self.group_trades`\"\"\"\n",
    "        exchanges = [x.split(\".\")[1] for x in t.names]\n",
    "        symbol = t.names[0].split(\".\")[-1]\n",
    "        starttime = t.entry_time.strftime(\"%Y-%m-%d\")\n",
    "        endtime = t.exit_time.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        # Rounding factors\n",
    "        spread_rf = 4 if (abs(t.entry_spread) < 1) else 2\n",
    "        price_rf = 4 if (sum([abs(x) for x in t.entry_prices]) / len(t.entry_prices)) < 1 else 2\n",
    "        size_rf = 3 if (sum(t.sizes) / len(t.sizes)) < 1 else 2\n",
    "\n",
    "        # direction symbols\n",
    "        d_sym = {-1: \"\\\\\", 1: \"/\"}\n",
    "\n",
    "        # direction strings\n",
    "        d_str = {-1: \"Short\", 1: \"Long\"}\n",
    "\n",
    "        entry_spread = t.entry_spread\n",
    "        filled_entry_spread = t.filled_entry_spread\n",
    "        entry_prices = [(x) for x in t.entry_prices]\n",
    "        filled_entry_prices = [(x) for x in t.filled_entry_prices]\n",
    "\n",
    "        entry_zscore = t.entry_zscore\n",
    "        exit_zscore = t.exit_zscore\n",
    "\n",
    "        exit_spread = t.exit_spread\n",
    "        filled_exit_spread = t.filled_exit_spread\n",
    "        exit_prices = [(x) for x in t.exit_prices]\n",
    "        filled_exit_prices = [(x) for x in t.filled_exit_prices]\n",
    "\n",
    "        spread_change = t.spread_change\n",
    "        spread_change_pct = 100 * spread_change / abs(entry_spread)\n",
    "        filled_spread_change = t.filled_spread_change\n",
    "        filled_spread_change_pct = 100 * filled_spread_change / abs(filled_entry_spread)\n",
    "\n",
    "        trade_value = sum(size * price for size, price in zip(t.sizes, t.entry_prices))\n",
    "        sizes = [(x) for x in t.sizes]\n",
    "        raw_pnl = sum(t.raw_pnl)\n",
    "        raw_returns = 100 * sum(t.raw_pnl) / trade_value\n",
    "        pnl_w_slip_fees = sum(t.pnl_w_slip_fees)\n",
    "        returns_w_slip_fees = 100 * sum(t.pnl_w_slip_fees) / trade_value\n",
    "\n",
    "        slippage = sum(t.entry_slippage) + sum(t.exit_slippage)\n",
    "        slippage_pct = 100 * slippage / trade_value\n",
    "        entry_slippage = sum(t.entry_slippage)\n",
    "        exit_slippage = sum(t.exit_slippage)\n",
    "\n",
    "        fees = sum(t.total_fees)\n",
    "        fee_pct = 100 * fees / trade_value\n",
    "        entry_fees = sum(t.entry_fees)\n",
    "        exit_fees = sum(t.exit_fees)\n",
    "\n",
    "        formatter = util.BashFormatter()\n",
    "\n",
    "        def add_color(x: str, x_float: float):\n",
    "            if x_float > 0:\n",
    "                return formatter.format(x, \"green\", \"black\", \"bold\")\n",
    "            elif x_float < 0:\n",
    "                return formatter.format(x, \"red\", \"black\", \"bold\")\n",
    "            else:\n",
    "                return formatter.format(x, \"orange\", \"black\", \"bold\")\n",
    "\n",
    "        def add_secondary_color(x: str, x_float: float):\n",
    "            if x_float > 0:\n",
    "                return formatter.color(x, \"light_green\")\n",
    "            elif x_float < 0:\n",
    "                return formatter.color(x, \"light_red\")\n",
    "            else:\n",
    "                return formatter.color(x, \"light_orange\")\n",
    "\n",
    "        margin = 25\n",
    "        trade_info = f\"\"\"\n",
    "        {'-'*130}\n",
    "        {'Info:':{margin}} {d_str[t.spread_dir]} {d_sym[t.spread_dir]} | {symbol} | ({exchanges[1]} - {exchanges[0]}) | {t.overall_status} | {starttime} --> {endtime} ({(t.exit_time - t.entry_time).days} days)\n",
    "        {'Cash:':{margin}} {f'Start[ {t.start_cash:7.2f}]':20} End[ {t.end_cash:7.2f}]\n",
    "        {'Entry Spread:':{margin}} {f'Inital[ {entry_spread: .{spread_rf}f} ({entry_prices[1]: .{spread_rf}f} - {entry_prices[0]: .{spread_rf}f})]':40} Filled[ {filled_entry_spread: .{spread_rf}f} ({filled_entry_prices[1]: .{spread_rf}f} - {filled_entry_prices[0]: .{spread_rf}f})]\n",
    "        {'Exit Spread:':{margin}} {f'Inital[ {exit_spread: .{spread_rf}f} ({exit_prices[1]: .{spread_rf}f} - {exit_prices[0]: .{spread_rf}f})]':40} Filled[ {filled_exit_spread: .{spread_rf}f} ({filled_exit_prices[1]: .{spread_rf}f} - {filled_exit_prices[0]: .{spread_rf}f})]\n",
    "        {'Spread change:':{margin}} {add_secondary_color(f'Inital[ {spread_change: .{spread_rf}f} ({spread_change_pct:.2f}%)]', spread_change):40} {add_secondary_color(f'Filled[ {filled_spread_change:.{spread_rf}f} ({filled_spread_change_pct:.2f}%)]', filled_spread_change)}\n",
    "        {'Trade Value:':{margin}} {trade_value:.2f} ({sizes[0]:.{size_rf}f}x{filled_entry_prices[0]:.{price_rf}f} + {sizes[1]:.{size_rf}f}x{filled_entry_prices[1]:.{price_rf}f})\n",
    "        {'Raw PnL:':{margin}} {add_secondary_color(f'{raw_pnl:8.2f} ({raw_returns: .2f}%)', raw_pnl)}\n",
    "        {'PnL (w/ slip & fees):':{margin}} {add_color(f'{pnl_w_slip_fees:8.2f} ({returns_w_slip_fees: .2f}%)', pnl_w_slip_fees)}\n",
    "        {'Z Score:':{margin}} {f'Entry[ {entry_zscore:7.2f}]':20} Exit[ {exit_zscore:7.2f}]\n",
    "        {'Slippage:':{margin}} {slippage:8.2f} ({slippage_pct:.2f}%) {f'Entry[ {entry_slippage:7.2f}]':20} Exit[ {exit_slippage:7.2f}]\n",
    "        {'Fees:':{margin}} {fees:8.2f} ({fee_pct:.2f}%) {f'Entry[ {entry_fees:7.2f}]':20} Exit[ {exit_fees:7.2f}]\n",
    "        \n",
    "        {'Exchange:':{margin}} {exchanges[0]:>10}   {exchanges[1]:>10}\n",
    "        {'Entry Price: ':{margin}} {f'{entry_prices[0]:.{price_rf}f}':>10}   {f'{entry_prices[1]:.{price_rf}f}':>10}\n",
    "        {'Entry Price (filled): ':{margin}} {f'{filled_entry_prices[0]:.{price_rf}f}':>10}   {f'{filled_entry_prices[1]:.{price_rf}f}':>10}\n",
    "        {'Exit Price: ':{margin}} {f'{exit_prices[0]:.{price_rf}f}':>10}   {f'{exit_prices[1]:.{price_rf}f}':>10}\n",
    "        {'Exit Price (filled): ':{margin}} {f'{filled_exit_prices[0]:.{price_rf}f}':>10}   {f'{filled_exit_prices[1]:.{price_rf}f}':>10}\n",
    "        {'Trade Size: ':{margin}} {f'{sizes[0]:.{size_rf}f}':>10}   {f'{sizes[1]:.{size_rf}f}':>10}\n",
    "        {'Trade Value: ':{margin}} {f'{sizes[0] * filled_entry_prices[0]:.{price_rf}f}':>10}   {f'{sizes[1] * filled_entry_prices[1]:.{price_rf}f}':>10}\n",
    "        {'Raw PnL: ':{margin}} {add_secondary_color(f'{t.raw_pnl[0]:.2f}', t.raw_pnl[0]):>10}   {add_secondary_color(f'{t.raw_pnl[1]:.2f}', t.raw_pnl[1]):>10}\n",
    "        {'slippage: ':{margin}} {f'{t.entry_slippage[0] + t.exit_slippage[0]:.2f}':>10}   {f'{t.entry_slippage[1] + t.exit_slippage[1]:.2f}':>10}\n",
    "        {'fees:':{margin}} {f'{t.total_fees[0]:.2f}':>10}   {f'{t.total_fees[1]:.2f}':>10}\n",
    "        {'PnL (w/ slip only):':{margin}} {f'{t.pnl_w_slip[0]:.2f}':>10}   {f'{t.pnl_w_slip[1]:.2f}':>10}\n",
    "        {'PnL (w/ fees only):':{margin}} {f'{t.pnl_w_fees[0]:.2f}':>10}   {f'{t.pnl_w_fees[1]:.2f}':>10}\n",
    "        {'PnL (w/ slip & fees):':{margin}} {f'{t.pnl_w_slip_fees[0]:.2f}':>10}   {f'{t.pnl_w_slip_fees[1]:.2f}':>10}\n",
    "        {'-'*130}\n",
    "        \"\"\"\n",
    "\n",
    "        return trade_info\n",
    "\n",
    "    def print_all_trades(self):\n",
    "        \"\"\"Print formatted trades to stdout\"\"\"\n",
    "        leg_trades = self.get_leg_trades()\n",
    "        if len(leg_trades) == 0:\n",
    "            print(\"No trades to show\")\n",
    "        else:\n",
    "            grouped_trades = (\n",
    "                leg_trades.sort_values([\"Entry Timestamp\", \"col\"])\n",
    "                .groupby(\"Entry Timestamp\", as_index=False)\n",
    "                .apply(self.group_trades)\n",
    "                .reset_index(level=1, drop=True)\n",
    "            )\n",
    "            for idx, trade in grouped_trades.iterrows():\n",
    "                print(self.format_trade(trade))\n",
    "\n",
    "    def aggregate_stats(self):\n",
    "        stats = pd.Series()\n",
    "        leg_trades = self.get_leg_trades()\n",
    "        if len(leg_trades) == 0:\n",
    "            stats[\"avg_fees\"] = np.nan\n",
    "            stats[\"avg_slippage\"] = np.nan\n",
    "            stats[\"avg_pnl\"] = np.nan\n",
    "            stats[\"profitable_trades\"] = 0\n",
    "            stats[\"losing_trades\"] = 0\n",
    "            stats[\"total_trades\"] = 0\n",
    "            return stats\n",
    "\n",
    "        grouped_trades = (\n",
    "            leg_trades.sort_values([\"Entry Timestamp\", \"col\"])\n",
    "            .groupby(\"Entry Timestamp\", as_index=False)\n",
    "            .apply(self.group_trades, sum_legs=True)\n",
    "            .reset_index(level=1, drop=True)\n",
    "        )\n",
    "        stats[\"avg_fees\"] = grouped_trades[\"total_fees\"].mean()\n",
    "        stats[\"avg_slippage\"] = grouped_trades[\"total_slippage\"].mean()\n",
    "        stats[\"avg_pnl\"] = grouped_trades[\"pnl_w_slip_fees\"].mean()\n",
    "        stats[\"profitable_trades\"] = (grouped_trades[\"pnl_w_slip_fees\"] > 0).sum()\n",
    "        stats[\"losing_trades\"] = (grouped_trades[\"pnl_w_slip_fees\"] < 0).sum()\n",
    "        stats[\"total_trades\"] = len(grouped_trades[grouped_trades.overall_status == \"Closed\"])\n",
    "        return stats\n",
    "\n",
    "class BacktestRunner:\n",
    "    def __init__(\n",
    "        self,\n",
    "        initial_cash=150000,\n",
    "        trade_value=10000,\n",
    "        vbt_function=app.vbt_backtest.from_order_func_wrapper,\n",
    "        z_score_period=z_score_period,\n",
    "        z_score_thresholds=(0, 1),  # (entry_threshold, exit_threshold)\n",
    "        use_slippage=True,\n",
    "        use_funding_rate=True,\n",
    "        profitable_only=True,      # Expected return on total trade size after fees and slippage\n",
    "        log_dir=None,\n",
    "        force_logging=False,\n",
    "    ):\n",
    "        self.initial_cash = initial_cash\n",
    "        self.trade_value = trade_value\n",
    "        self.vbt_function = vbt_function\n",
    "        self.z_score_period = z_score_period\n",
    "        self.z_score_thresholds = z_score_thresholds\n",
    "        self.use_slippage = use_slippage\n",
    "        self.use_funding_rate = use_funding_rate\n",
    "        self.profitable_only = profitable_only\n",
    "\n",
    "        self.logging = force_logging or (log_dir is not None)\n",
    "        if log_dir is not None:\n",
    "            self.log_dir = self.make_log_dir(log_dir)\n",
    "\n",
    "    @staticmethod\n",
    "    def make_log_dir(path):\n",
    "        time_now = datetime.now()\n",
    "        date_now = time_now.date().strftime(\"%Y-%m-%d\")\n",
    "        hour_now = time_now.strftime(\"%H\")\n",
    "        minute_now = time_now.strftime(\"%M\")\n",
    "        full_log_dir = os.path.join(path, date_now, hour_now, minute_now)\n",
    "        os.makedirs(full_log_dir, exist_ok=True)\n",
    "        return full_log_dir\n",
    "\n",
    "    @staticmethod\n",
    "    def unique_file_name(path):\n",
    "        i = 2\n",
    "        while os.path.exists(path):\n",
    "            path = f\"{path}_{i}\"\n",
    "            i += 1\n",
    "        return f\"{path}.log\"\n",
    "\n",
    "    def _run_single_spread(self, row: pd.Series):\n",
    "        spread: Spread = pickle.loads(row.spread)\n",
    "        alias = row.alias\n",
    "\n",
    "        close_prices = np.array(spread.underlying_col(\"close\"))\n",
    "\n",
    "        if not self.use_funding_rate:\n",
    "            zero_funding_rate = pd.DataFrame({\"timestamp\": spread.time_only, \"funding_rate\": [0] * len(spread)})\n",
    "            spread.add_funding_rate(zero_funding_rate, zero_funding_rate)\n",
    "\n",
    "        if not self.use_slippage:\n",
    "            zero_bid_ask_spread = pd.DataFrame({\"date\": spread.time_only, \"bid_ask_spread\": [0] * len(spread)})\n",
    "            spread.add_bid_ask_spread(zero_bid_ask_spread, zero_bid_ask_spread)\n",
    "\n",
    "        funding_rate = np.array(spread.underlying_col(\"funding_rate\"))\n",
    "        bid_ask_spread = np.array(spread.underlying_col(\"bid_ask_spread\"))\n",
    "\n",
    "        zscore = np.array(spread.zscore(period=self.z_score_period))\n",
    "        setattr(spread, \"zscore_period\", self.z_score_period)\n",
    "        var = tuple(zip(spread.value_at_risk(percentile=5), spread.value_at_risk(percentile=95)))\n",
    "\n",
    "        fee_info = {}\n",
    "        fee_info_a = pickle.loads(row.fee_info_a)\n",
    "        fee_info_b = pickle.loads(row.fee_info_b)\n",
    "        for key in [\"init_margin\", \"maint_margin\", \"fee_pct\", \"fee_fixed\"]:\n",
    "            fee_info[key] = (fee_info_a[key], fee_info_b[key])\n",
    "\n",
    "        bt_args = app.vbt_backtest.BacktestArgs(\n",
    "            initial_cash=self.initial_cash,\n",
    "            trade_value=self.trade_value,\n",
    "            z_score_thresholds=self.z_score_thresholds,\n",
    "            var=var,\n",
    "            init_margin=fee_info[\"init_margin\"],\n",
    "            maint_margin=fee_info[\"maint_margin\"],\n",
    "            fee_pct=fee_info[\"fee_pct\"],\n",
    "            fee_fixed=fee_info[\"fee_fixed\"],\n",
    "            zscore=zscore,\n",
    "            funding_rate=funding_rate,\n",
    "            bid_ask_spread=bid_ask_spread,\n",
    "            logging=self.logging,\n",
    "            profitable_only=self.profitable_only,\n",
    "        )\n",
    "        if hasattr(self, \"log_dir\"):\n",
    "            log_file_name = os.path.join(self.log_dir, self.unique_file_name(alias))\n",
    "            bt_func = util.redirect_stdout(log_file_name)(self.vbt_function)\n",
    "        else:\n",
    "            bt_func = self.vbt_function\n",
    "        res = bt_func(close_prices, bt_args)\n",
    "        res = res.replace(\n",
    "            wrapper=res.wrapper.replace(\n",
    "                index=spread.open_time, columns=spread.underlying_col(\"close\").columns.get_level_values(0)\n",
    "            )\n",
    "        )\n",
    "        return BacktestResult(res, spread)\n",
    "\n",
    "    def run(self, spreads: pd.DataFrame, exchange_subset=[], inst_type_subset=[\"perpetual\"], symbol_subset=[]):\n",
    "        index_filter = pd.MultiIndex.from_product(\n",
    "            [exchange_subset, exchange_subset, inst_type_subset, inst_type_subset, symbol_subset]\n",
    "        )\n",
    "        if len(index_filter) > 0:\n",
    "            spreads = spreads.filter(index_filter, axis=0)\n",
    "\n",
    "        results = spreads.apply(self._run_single_spread, axis=1)\n",
    "        return results\n",
    "    \n",
    "    def run_chained(self, spreads: pd.DataFrame):\n",
    "        leg_0_close = np.array(spreads.apply(lambda s: pickle.loads(s.spread).underlying_col(\"close\").T.iloc[0], axis=1))\n",
    "        leg_1_close = np.array(spreads.apply(lambda s: pickle.loads(s.spread).underlying_col(\"close\").T.iloc[1], axis=1))\n",
    "        close_prices = np.concatenate([leg_0_close, leg_1_close], axis=0).T\n",
    "        \n",
    "        if not self.use_funding_rate:\n",
    "            funding_rate = np.stack(spreads.apply(lambda s: np.zeros((2, len(pickle.loads(s.spread)))), axis=1), axis=1).T\n",
    "        else:\n",
    "            funding_rate = np.stack(spreads.apply(lambda s: pickle.loads(s.spread).underlying_col(\"funding_rate\").T, axis=1), axis=1).T\n",
    "\n",
    "        if not self.use_slippage:\n",
    "            bid_ask_spread = np.stack(spreads.apply(lambda s: np.zeros((2, len(pickle.loads(s.spread)))), axis=1), axis=1).T\n",
    "        else:\n",
    "            bid_ask_spread = np.stack(spreads.apply(lambda s: pickle.loads(s.spread).underlying_col(\"bid_ask_spread\").T, axis=1), axis=1).T\n",
    "\n",
    "        zscore = np.array(spreads.apply(lambda s: pickle.loads(s.spread).zscore(\"close\", self.z_score_period), axis=1)).T\n",
    "        var = np.stack(spreads.apply(lambda s: np.array([*zip(pickle.loads(s.spread).value_at_risk(percentile=5), pickle.loads(s.spread).value_at_risk(percentile=95))]), axis=1).T)\n",
    "        fee_info_a = spreads.apply(lambda s: pd.Series(pickle.loads(s.fee_info_a)), axis=1)\n",
    "        fee_info_b = spreads.apply(lambda s: pd.Series(pickle.loads(s.fee_info_b)), axis=1)\n",
    "        \n",
    "        bt_args = app.vbt_backtest.BacktestArgs(\n",
    "            initial_cash=self.initial_cash,\n",
    "            trade_value=self.trade_value,\n",
    "            z_score_thresholds=self.z_score_thresholds,\n",
    "            var=var,\n",
    "            init_margin=np.array([fee_info_a.init_margin, fee_info_b.init_margin]).T,\n",
    "            maint_margin=np.array([fee_info_a.maint_margin, fee_info_b.maint_margin]).T,\n",
    "            fee_pct=np.array([fee_info_a.fee_pct, fee_info_b.fee_pct]).T,\n",
    "            fee_fixed=np.array([fee_info_a.fee_fixed, fee_info_b.fee_fixed]).T,\n",
    "            zscore=zscore,\n",
    "            funding_rate=funding_rate,\n",
    "            bid_ask_spread=bid_ask_spread,\n",
    "            logging=self.logging,\n",
    "            profitable_only=self.profitable_only,\n",
    "        )\n",
    "        \n",
    "        if hasattr(self, \"log_dir\"):\n",
    "            log_file_name = os.path.join(self.log_dir, self.unique_file_name(f\"{len(spreads)}_chained\"))\n",
    "            bt_func = util.redirect_stdout(log_file_name)(self.vbt_function)\n",
    "        else:\n",
    "            bt_func = self.vbt_function\n",
    "        res = bt_func(close_prices, bt_args)\n",
    "        \n",
    "        col_0_names = np.array(spreads.apply(lambda s: pickle.loads(s.spread).underlying_col(\"close\").columns.get_level_values(0)[0], axis=1))\n",
    "        col_1_names = np.array(spreads.apply(lambda s: pickle.loads(s.spread).underlying_col(\"close\").columns.get_level_values(0)[1], axis=1))\n",
    "        col_names = np.concatenate([col_0_names, col_1_names], axis=0)\n",
    "        res = res.replace(\n",
    "            wrapper=res.wrapper.replace(\n",
    "                index=pickle.loads(spreads.iloc[0].spread).time_only, columns=col_names\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spreads.to_pickle(\"spreads_2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"spreads_2.pkl\", \"rb\") as f:\n",
    "    spreads = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlcvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.dummy import dummy_bid_ask_spreads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dummy_bid_ask_spreads(ohlcvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.loads(x.iloc[0].bid_ask_spread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.loads(x.iloc[0].ohlcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.loads(spreads.iloc[488].spread).underlying_col(\"close\")[80:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btrunner = BacktestRunner(\n",
    "    log_dir=os.path.join(\n",
    "        os.getenv(\"ACTIVE_DEV_PATH\", \"/home/stefano/development/active_dev\"), \"logs\", backtest_identifier\n",
    "    ),\n",
    "    use_slippage=False,\n",
    "    use_funding_rate=False,\n",
    "    profitable_only=True,\n",
    "    z_score_thresholds=(0, 1),\n",
    "    vbt_function=from_order_func_wrapper_chained,\n",
    ")\n",
    "res = btrunner.run_chained(spreads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ChainedBacktestResult(res, spreads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.orders.records_readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leg_trades = result.get_leg_trades()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_client.ohlcv(\"bitmex\", \"DOGE\", \"perpetual\", starttime=datetime(2023, 5, 3, 12), endtime=datetime(2023, 5, 5, 3), interval=cm.Interval.interval_1h, cache_kwargs={\"disabled\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_client.ohlcv(\"binance\", \"DOGE\", \"perpetual\", starttime=datetime(2023, 5, 3, 12), endtime=datetime(2023, 5, 5, 3), interval=cm.Interval.interval_1h, cache_kwargs={\"disabled\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.print_all_trades()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio = res\n",
    "orders = portfolio.orders.records_readable.sort_values([\"Timestamp\", \"Order Id\"])\n",
    "orders[\"col\"] = portfolio.orders.records.sort_values(\"idx\").col\n",
    "try:\n",
    "    orders[\"When\"] = pd.concat(\n",
    "        [pd.Series([\"entry\", \"exit\"]).repeat(2)] * int(np.ceil(len(orders) / 4)), ignore_index=True\n",
    "    ).values[: len(orders)]\n",
    "except ValueError:\n",
    "    orders[\"When\"] = pd.Series()\n",
    "orders = orders.rename(columns={\"Price\": \"filled_price\", \"Size\": \"size\"})\n",
    "orders\n",
    "close_prices = pd.concat(\n",
    "    [\n",
    "        pickle.loads(spreads.iloc[i].spread)\n",
    "        .underlying_col(\"close\")\n",
    "        .droplevel(1, axis=1)\n",
    "        .set_axis([i, i + len(spreads)], axis=1)\n",
    "        .melt(var_name=\"col\", value_name=\"close\", ignore_index=False)\n",
    "        .reset_index()\n",
    "        .rename(columns={\"open_time\": \"Timestamp\"})\n",
    "        for i in range(len(spreads))\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "zscores = pd.concat(\n",
    "    [\n",
    "        pickle.loads(spreads.iloc[i].spread).zscore(period=30).to_frame().assign(col=i)\n",
    "        for i in range(len(spreads))\n",
    "    ],\n",
    "    axis=0,\n",
    ").reset_index()\n",
    "zscores = pd.concat([zscores, zscores.assign(col=zscores.col + zscores.col.nunique())], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "slippage = orders.merge(close_prices, left_on=[\"Timestamp\", \"col\"], right_on=[\"Timestamp\", \"col\"], how=\"left\")\n",
    "slippage[\"slippage\"] = abs(slippage[\"close\"] - slippage[\"filled_price\"]) * slippage[\"size\"]\n",
    "slippage = slippage[[\"Timestamp\", \"col\", \"slippage\", \"When\"]]\n",
    "entry_slippage = (\n",
    "    slippage[slippage.When == \"entry\"]\n",
    "    .rename(columns={\"slippage\": \"entry_slippage\", \"Timestamp\": \"Entry Timestamp\"})\n",
    "    .drop(columns=\"When\")\n",
    ")\n",
    "exit_slippage = (\n",
    "    slippage[slippage.When == \"exit\"]\n",
    "    .rename(columns={\"slippage\": \"exit_slippage\", \"Timestamp\": \"Exit Timestamp\"})\n",
    "    .drop(columns=\"When\")\n",
    ")\n",
    "leg_trades = portfolio.trades.records_readable.sort_values(\"Entry Timestamp\")\n",
    "leg_trades[\"col\"] = portfolio.trades.records.sort_values(\"entry_idx\").col\n",
    "leg_trades = leg_trades.merge(\n",
    "    zscores.rename(columns={\"zscore\": \"entry_zscore\"}),\n",
    "    left_on=[\"Entry Timestamp\", \"col\"],\n",
    "    right_on=[\"open_time\", \"col\"],\n",
    "    how=\"left\",\n",
    ").drop(columns=\"open_time\")\n",
    "leg_trades = leg_trades.merge(\n",
    "    zscores.rename(columns={\"zscore\": \"exit_zscore\"}),\n",
    "    left_on=[\"Exit Timestamp\", \"col\"],\n",
    "    right_on=[\"open_time\", \"col\"],\n",
    "    how=\"left\",\n",
    ").drop(columns=\"open_time\")\n",
    "\n",
    "leg_trades = leg_trades.merge(\n",
    "    portfolio.cash().rename(\"entry_cash\"), left_on=\"Entry Timestamp\", right_index=True\n",
    ")\n",
    "leg_trades = leg_trades.merge(portfolio.cash().rename(\"exit_cash\"), left_on=\"Exit Timestamp\", right_index=True)\n",
    "leg_trades = leg_trades.merge(entry_slippage)\n",
    "leg_trades = leg_trades.merge(exit_slippage, how=\"left\")  # Left merge because last trade may not be closed\n",
    "leg_trades = leg_trades.merge(close_prices.rename(columns={\"Timestamp\": \"Entry Timestamp\"})).rename(\n",
    "    columns={\"close\": \"entry_price\"}\n",
    ")\n",
    "leg_trades = leg_trades.merge(close_prices.rename(columns={\"Timestamp\": \"Exit Timestamp\"})).rename(\n",
    "    columns={\"close\": \"exit_price\"}\n",
    ")\n",
    "leg_trades[\"slippage\"] = leg_trades[\"entry_slippage\"] + leg_trades[\"exit_slippage\"]\n",
    "leg_trades[\"fees\"] = leg_trades[\"Entry Fees\"] + leg_trades[\"Exit Fees\"]\n",
    "leg_trades.rename(columns={\"PnL\": \"PnL w fees\"}, inplace=True)\n",
    "leg_trades[\"raw PnL\"] = leg_trades[\"PnL w fees\"] + leg_trades[\"fees\"]\n",
    "leg_trades[\"PnL w slip\"] = leg_trades[\"raw PnL\"] - leg_trades[\"slippage\"]\n",
    "leg_trades[\"PnL w slip + fees\"] = leg_trades[\"PnL w fees\"] - leg_trades[\"slippage\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.cash().to_csv(\"cash.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.trades.records_readable.sort_values(\"Entry Timestamp\").merge(res.value(), left_on=\"Entry Timestamp\", right_index=True, how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.value().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.print_all_trades()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "for idx, row in spreads.iterrows():\n",
    "    try:\n",
    "        res = btrunner._run_single_spread(row)\n",
    "    except:\n",
    "        print(\"error: \", idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all\n",
    "results = btrunner.run(spreads).to_frame(\"result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"total_return\"] = results.result.apply(lambda e: e.portfolio.total_return())\n",
    "results[\"total_profit\"] = results.result.apply(lambda e: e.portfolio.total_profit())\n",
    "results = results.join(results.result.apply(lambda e: e.aggregate_stats()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"by total_return\")\n",
    "display(results.sort_values(\"total_return\").tail(7))\n",
    "print(\"99th percentile: \")\n",
    "display(results.sort_values(\"total_return\").quantile(0.99))\n",
    "display(results.total_return.plot.kde())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(results.avg_fees.plot.kde())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(results.avg_slippage.plot.kde())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(results.avg_pnl.plot.kde())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('spread-arb')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "edf662c7edfc0f240a8419c34f99e66382b4b464e505b20dc3583bda2481e3a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
